Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/03/07 13:54:20 WARN Utils: Your hostname, bolot-BOHK-WAX9X resolves to a loopback address: 127.0.1.1; using 172.100.15.137 instead (on interface enx00133ba9f97f)
23/03/07 13:54:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/03/07 13:54:20 INFO SparkContext: Running Spark version 3.3.2
23/03/07 13:54:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/03/07 13:54:20 INFO ResourceUtils: ==============================================================
23/03/07 13:54:20 INFO ResourceUtils: No custom resources configured for spark.driver.
23/03/07 13:54:20 INFO ResourceUtils: ==============================================================
23/03/07 13:54:20 INFO SparkContext: Submitted application: SparkTrafficMonitoring
23/03/07 13:54:20 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/03/07 13:54:20 INFO ResourceProfile: Limiting resource is cpu
23/03/07 13:54:20 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/03/07 13:54:20 INFO SecurityManager: Changing view acls to: bolot
23/03/07 13:54:20 INFO SecurityManager: Changing modify acls to: bolot
23/03/07 13:54:20 INFO SecurityManager: Changing view acls groups to: 
23/03/07 13:54:20 INFO SecurityManager: Changing modify acls groups to: 
23/03/07 13:54:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(bolot); groups with view permissions: Set(); users  with modify permissions: Set(bolot); groups with modify permissions: Set()
23/03/07 13:54:21 INFO Utils: Successfully started service 'sparkDriver' on port 33697.
23/03/07 13:54:21 INFO SparkEnv: Registering MapOutputTracker
23/03/07 13:54:21 INFO SparkEnv: Registering BlockManagerMaster
23/03/07 13:54:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/03/07 13:54:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/03/07 13:54:21 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/03/07 13:54:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d48415f6-1d2c-4487-ab0f-3fb0ae96f0d0
23/03/07 13:54:21 INFO MemoryStore: MemoryStore started with capacity 852.0 MiB
23/03/07 13:54:21 INFO SparkEnv: Registering OutputCommitCoordinator
23/03/07 13:54:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/03/07 13:54:21 INFO Executor: Starting executor ID driver on host cpe-172-100-15-137.twcny.res.rr.com
23/03/07 13:54:21 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/03/07 13:54:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38071.
23/03/07 13:54:21 INFO NettyBlockTransferService: Server created on cpe-172-100-15-137.twcny.res.rr.com:38071
23/03/07 13:54:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/03/07 13:54:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, cpe-172-100-15-137.twcny.res.rr.com, 38071, None)
23/03/07 13:54:21 INFO BlockManagerMasterEndpoint: Registering block manager cpe-172-100-15-137.twcny.res.rr.com:38071 with 852.0 MiB RAM, BlockManagerId(driver, cpe-172-100-15-137.twcny.res.rr.com, 38071, None)
23/03/07 13:54:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, cpe-172-100-15-137.twcny.res.rr.com, 38071, None)
23/03/07 13:54:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, cpe-172-100-15-137.twcny.res.rr.com, 38071, None)
23/03/07 13:54:22 INFO FileInputDStream: Duration for remembering RDDs set to 60000 ms for org.apache.spark.streaming.dstream.FileInputDStream@6436e181
23/03/07 13:54:25 INFO FileInputDStream: Slide time = 5000 ms
23/03/07 13:54:25 INFO FileInputDStream: Storage level = Serialized 1x Replicated
23/03/07 13:54:25 INFO FileInputDStream: Checkpoint interval = null
23/03/07 13:54:25 INFO FileInputDStream: Remember interval = 60000 ms
23/03/07 13:54:25 INFO FileInputDStream: Initialized and validated org.apache.spark.streaming.dstream.FileInputDStream@6436e181
23/03/07 13:54:25 INFO MappedDStream: Slide time = 5000 ms
23/03/07 13:54:25 INFO MappedDStream: Storage level = Serialized 1x Replicated
23/03/07 13:54:25 INFO MappedDStream: Checkpoint interval = null
23/03/07 13:54:25 INFO MappedDStream: Remember interval = 5000 ms
23/03/07 13:54:25 INFO MappedDStream: Initialized and validated org.apache.spark.streaming.dstream.MappedDStream@1fe59e6e
23/03/07 13:54:25 INFO TransformedDStream: Slide time = 5000 ms
23/03/07 13:54:25 INFO TransformedDStream: Storage level = Serialized 1x Replicated
23/03/07 13:54:25 INFO TransformedDStream: Checkpoint interval = null
23/03/07 13:54:25 INFO TransformedDStream: Remember interval = 5000 ms
23/03/07 13:54:25 INFO TransformedDStream: Initialized and validated org.apache.spark.streaming.dstream.TransformedDStream@39ab1ef2
23/03/07 13:54:25 INFO TransformedDStream: Slide time = 5000 ms
23/03/07 13:54:25 INFO TransformedDStream: Storage level = Serialized 1x Replicated
23/03/07 13:54:25 INFO TransformedDStream: Checkpoint interval = null
23/03/07 13:54:25 INFO TransformedDStream: Remember interval = 5000 ms
23/03/07 13:54:25 INFO TransformedDStream: Initialized and validated org.apache.spark.streaming.dstream.TransformedDStream@506d7569
23/03/07 13:54:25 INFO TransformedDStream: Slide time = 5000 ms
23/03/07 13:54:25 INFO TransformedDStream: Storage level = Serialized 1x Replicated
23/03/07 13:54:25 INFO TransformedDStream: Checkpoint interval = null
23/03/07 13:54:25 INFO TransformedDStream: Remember interval = 5000 ms
23/03/07 13:54:25 INFO TransformedDStream: Initialized and validated org.apache.spark.streaming.dstream.TransformedDStream@253f76fa
23/03/07 13:54:25 INFO TransformedDStream: Slide time = 5000 ms
23/03/07 13:54:25 INFO TransformedDStream: Storage level = Serialized 1x Replicated
23/03/07 13:54:25 INFO TransformedDStream: Checkpoint interval = null
23/03/07 13:54:25 INFO TransformedDStream: Remember interval = 5000 ms
23/03/07 13:54:25 INFO TransformedDStream: Initialized and validated org.apache.spark.streaming.dstream.TransformedDStream@169a9add
23/03/07 13:54:25 INFO ForEachDStream: Slide time = 5000 ms
23/03/07 13:54:25 INFO ForEachDStream: Storage level = Serialized 1x Replicated
23/03/07 13:54:25 INFO ForEachDStream: Checkpoint interval = null
23/03/07 13:54:25 INFO ForEachDStream: Remember interval = 5000 ms
23/03/07 13:54:25 INFO ForEachDStream: Initialized and validated org.apache.spark.streaming.dstream.ForEachDStream@77a74a72
23/03/07 13:54:25 INFO RecurringTimer: Started timer for JobGenerator at time 1678193670000
23/03/07 13:54:25 INFO JobGenerator: Started JobGenerator at 1678193670000 ms
23/03/07 13:54:25 INFO JobScheduler: Started JobScheduler
23/03/07 13:54:25 INFO StreamingContext: StreamingContext started
23/03/07 13:54:30 INFO FileInputDStream: New files at time 1678193670000 ms:

23/03/07 13:54:30 WARN SparkTrafficMonitoring: [Source] latency: 54727602
23/03/07 13:54:30 WARN SparkTrafficMonitoring: [Source] bandwidth: 0.00000 MB/s
